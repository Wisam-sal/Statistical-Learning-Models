{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a22f08",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "A Comparison between Statistical Classification Models' ability to learn and identify Human vs. Robot based on movement patterns and trajectory.\n",
    "\n",
    "### The Data\n",
    "\n",
    "Annotated dataset for multi-camera tracking and 2D/3D object detection.\n",
    "\n",
    "- **Data Source:**  \n",
    "  [NVIDIA PhysicalAI SmartSpaces Dataset (Hugging Face)](https://huggingface.co/datasets/nvidia/PhysicalAI-SmartSpaces)\n",
    "\n",
    "- **Data Description:**  \n",
    "  - Consists of videos from indoor scenes (warehouses, hospitals, retail spaces).\n",
    "  - Time-synchronized to track humans and robots across multiple cameras.\n",
    "  - For this project, we use the **calibration** and **ground truth annotation** files from a 5-minute simulation.\n",
    "  - Each frame captures:\n",
    "    - Bounding boxes of each object in each camera view.\n",
    "    - Pixel area (feature) and Euclidean distance from the origin (target).\n",
    "  - The training dataset contains **14 different warehouses**, each with:\n",
    "    - A varying number of cameras.\n",
    "    - A varying number of moving units (Humans/Robots).\n",
    "\n",
    "### Predictors and Response\n",
    "The dataset's starting point is the tracked movement of a unit within the space as captured by the sensors. \n",
    "The data processing invloves collecting statistics about the unit's movement.\n",
    "\n",
    "- Input Features: \n",
    "  First and second order statistics of a unit's movement and trajectory within the physical space as captured by the SmarSpace sensors, including:\n",
    "  * minimal distance from origin (center of map).\n",
    "  * Maximal distance from origin.\n",
    "  * Range of the trajectory.\n",
    "  * Total distance traveled.\n",
    "  * Proportion of the sensors capturing the movement; hinting at the unit's position relative to overall area coverage.\n",
    "\n",
    "- Target Variable: \n",
    "  **Human vs. Robot**\n",
    "\n",
    "### Models\n",
    "  - Logistic Regression\n",
    "  - Discriminant Analysis\n",
    "  - Support Vector Machine\n",
    "  - Random Forest\n",
    "  - Gradient Booster\n",
    "\n",
    "### Performance Metrics\n",
    "All models are compared and benchmarked against each other on the following metrics:\n",
    "  - **Balanced Accuracy** - Measuring overall correctness.\n",
    "\n",
    "  - **True Positive Rate (Sensitivity/Recall)** - Measuring the ability to detect the positives (Robots).\n",
    "  - **True Negative Rate (Specificity)** - Measuring the ability to detect the negatives (Humans).\n",
    "  - **Positive Predictive Value (Precision)** - Measuring how many predicted positives are true.\n",
    "  - **Negative Predictive Value** - Measuring how many predicted negatives are true.\n",
    "  - **F1 Score** - Measuring a balance between precision and recall.\n",
    "  - **Area Under the ROC Curve (AUC)** - Measuring a threshold-independent model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c728c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Fetching\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from src.config import PROCESSED_DATA_DIR\n",
    "from src.classification_utils import *\n",
    "from src.utils import plotly_to_confluence\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "csv_path = PROCESSED_DATA_DIR / \"all_units_statistics.csv\" \n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df['UNIT_TYPE'] = df['UNIT_TYPE'].str.replace('Forklift','Robot')\\\n",
    "                                            .replace('NovaCarter','Robot')\\\n",
    "                                            .replace('Transporter','Robot')\\\n",
    "                                            .replace('AgilityDigit','Robot')\\\n",
    "                                            .replace('FourierGR1T2','Robot')\n",
    "\n",
    "relevant_columns = [# 'MIN_LOC_X',                        \n",
    "                    # 'MIN_LOC_Y',                        \n",
    "                    'MIN_DIST_ORIGIN',                  \n",
    "                    # 'MAX_LOC_X',                        \n",
    "                    # 'MAX_LOC_Y',                        \n",
    "                    'MAX_DIST_ORIGIN',                  \n",
    "                    # 'MEAN_LOC_X',                       \n",
    "                    # 'MEAN_LOC_Y',                       \n",
    "                    # 'MEAN_DIST_ORIGIN',                 \n",
    "                    # 'STD_LOC_X',                        \n",
    "                    # 'STD_LOC_Y',                        \n",
    "                    # 'STD_DIST_ORIGIN',                  \n",
    "                    # 'MEDIAN_LOC_X',                     \n",
    "                    # 'MEDIAN_LOC_Y',                     \n",
    "                    # 'MEDIAN_DIST_ORIGIN',               \n",
    "                    # 'RANGE_LOC_X',                      \n",
    "                    # 'RANGE_LOC_Y',                      \n",
    "                    'RANGE_DIST_ORIGIN',                \n",
    "                    # 'TOTAL_DIST_TRAVELED_X',            \n",
    "                    # 'TOTAL_DIST_TRAVELED_Y',            \n",
    "                    'TOTAL_DIST_TRAVELED_EUCLIDEAN',    \n",
    "                    # 'TOTAL_DIRECTION_CHANGES',          \n",
    "                    # 'TIME_SPENT_WALKING_SEC',           \n",
    "                    # 'TIME_SPENT_STANDING_SEC',          \n",
    "                    'RATIO_OF_CAMERA_CAPTURES',         \n",
    "                    # 'UNIT_ID',                                              \n",
    "                    # 'WAREHOUSE', \n",
    "                    'UNIT_TYPE']\n",
    "\n",
    "df = df[relevant_columns]\n",
    "print('DataFrame Head:')\n",
    "display(df.head(10))\n",
    "print(f'DataFrame Shape: {df.shape}')\n",
    "print(f'DataFrame description:')\n",
    "display(df.describe())\n",
    "print('Missing values count:')\n",
    "display(df.isna().sum())\n",
    "print('Targets value counts:')\n",
    "display(df.UNIT_TYPE.value_counts()) # This is the binary target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Train Test Split + Performance Tuning Params\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "random_state = 42\n",
    "train_test_split_ratio = 0.2\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "X = df.drop(columns=['UNIT_TYPE'])\n",
    "y = (df['UNIT_TYPE'] == 'Robot').astype(int)  # Binary target: Robot=1, Person=0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=train_test_split_ratio, \n",
    "                                                    stratify=y, random_state=random_state)\n",
    "\n",
    "df = df.iloc[X_train.shape[0]*[True] + X_test.shape[0]*[False]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data vizualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.pairplot(df, hue=\"UNIT_TYPE\", diag_kind=\"kde\", height=2, aspect=1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 7))\n",
    "axes = axes.flatten()\n",
    "numeric_columns = [col for col in df.columns if col != 'UNIT_TYPE']\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    sns.boxplot(x='UNIT_TYPE', y=col, data=df, ax=axes[i])\n",
    "    axes[i].set_title(f'{col}')\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "features = df[[col for col in relevant_columns if 'UNIT_TYPE' not in col]]\n",
    "labels = df['UNIT_TYPE']\n",
    "label_names = np.unique(labels)\n",
    "label_to_int = {name: i for i, name in enumerate(label_names)}\n",
    "int_labels = np.array([label_to_int[label] for label in labels])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pd.DataFrame(features, columns=features.columns).corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.xticks(rotation=45, fontsize=8) \n",
    "plt.yticks(fontsize=8)      \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a201704",
   "metadata": {},
   "source": [
    "### Classification Metrics used\n",
    "- **TP (True Positive)**: Correctly predicted positive cases  \n",
    "- **TN (True Negative)**: Correctly predicted negative cases  \n",
    "- **FP (False Positive)**: Incorrectly predicted positive cases (Type I error)  \n",
    "- **FN (False Negative)**: Incorrectly predicted negative cases (Type II error)\n",
    "\n",
    "| Metric                        | Formula                                                               |\n",
    "|------------------------------|----------------------------------------------------------------------------------------|\n",
    "| **Balanced Accuracy**        | $(\\text{Sensitivity} + \\text{Specificity}) / 2$                                       |\n",
    "| **Sensitivity (Recall, TPR)**| $TP / (TP + FN)$                                                                      |\n",
    "| **Specificity (TNR)**        | $TN / (TN + FP)$                                                                      |\n",
    "| **Precision (PPV)**          | $TP / (TP + FP)$                                                                      |\n",
    "| **Negative Predictive Value (NPV)** | $TN / (TN + FN)$                                                              |\n",
    "| **F1 Score**                 | $2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Sensitivity}}{\\text{Precision} + \\text{Sensitivity}}$ |\n",
    "| **AUC**                      | Measures the model’s ability to distinguish between classes across all classification thresholds.                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7978d1",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic regression models the probability of a binary outcome $ Y \\in \\{0, 1\\} $ as a function of predictors $ X \\in \\mathbb{R}^p $.\n",
    "\n",
    "The model:\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{\\mathbb{P}(Y=1 \\mid X)}{\\mathbb{P}(Y=0 \\mid X)}\\right) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "- The left-hand side is the **logit**.\n",
    "- Estimation is done via **maximum likelihood**.\n",
    "- Output is a probability of class.\n",
    "\n",
    "The model assumes:\n",
    "- Assumes linearity in the log-odds.\n",
    "- No multicollinearity between predictors.\n",
    "- Independent observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c8734",
   "metadata": {},
   "source": [
    "The **Box-Tidwell Test** checks the linearity of continuous predictors with the log-odds in logistic regression model.\n",
    "\n",
    "For each predictor $x$, the test adds a term $x \\cdot log(x)$ to the model:\n",
    "\n",
    "$$\n",
    "log (\\frac{p}{1-p}) = \\beta_0 + \\beta_1 \\cdot x + \\beta_2 \\cdot x\\cdot log(x)\n",
    "$$\n",
    "\n",
    "$\\Rightarrow$ if $\\beta_2$ is not statistically significant, the relationship between log-odds and $x$ is likely linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca07ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Log Odds linearity Check\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = (df['UNIT_TYPE'] == 'Robot').astype(int)\n",
    "X = df.drop(columns=['UNIT_TYPE'])\n",
    "\n",
    "# Removing non-positive values to avoid log(0) and log(negative)\n",
    "X = X[(X > 0).all(axis=1)]\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Box-Tidwell transformed terms\n",
    "for col in X.columns:\n",
    "    X[f'{col}_log'] = X[col] * np.log(X[col])\n",
    "\n",
    "# intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit logistic regression\n",
    "model = sm.Logit(y, X).fit(disp=0) \n",
    "\n",
    "# p-values of interaction terms\n",
    "pvals = model.pvalues\n",
    "box_tidwell_pvals = pvals[pvals.index.str.endswith('_log')]\n",
    "\n",
    "# Plot\n",
    "minus_log_p = -np.log10(box_tidwell_pvals)\n",
    "plt.figure(figsize=(10, 5))\n",
    "minus_log_p.sort_values().plot(kind='barh', color='steelblue')\n",
    "plt.axvline(-np.log10(0.05), color='red', linestyle='--', label='α = 0.05')\n",
    "plt.xlabel('-log10(p-value)')\n",
    "plt.title('Box-Tidwell Nonlinearity Test', fontsize=10)\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5849c7",
   "metadata": {},
   "source": [
    "* None of the bars in the $-log_{10}(\\beta_2 \\ p-value)$ plot pass the red $α = 0.05$ threshold line; All p-values are greater than $0.05$.\n",
    "* Fail to reject the null hypothesis; No evidence of nonlinearity for any feature.\n",
    "\n",
    "$\\Rightarrow$ The Logistic Regression assumption holds for the non-correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a logistic regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "# ----------------------------------------- Model Parameters  -----------------------------------------\n",
    "\n",
    "auto_best_threshold_based_on_metric = 'accuracy'      # Available metrics: [\"accuracy\", \"sensitivity\", \"specificity\", \"ppv\", \"npv\", \"f1\", \"auc\"]\n",
    "include_bootstrap_confidence_intervals = True        # True # False\n",
    "cross_validation_splits = 5                           # 5-Fold cross validation\n",
    "grid_search_scoring_metric = 'roc_auc'                 # choosing best metric in grid search : ['roc_auc','recall']\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=cross_validation_splits, shuffle=True, random_state=random_state)\n",
    "grid = GridSearchCV(logreg, param_grid, cv=cv, scoring=grid_search_scoring_metric, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression Best parameters:\", grid.best_params_)\n",
    "# Test set evaluation\n",
    "best_model = grid.best_estimator_\n",
    "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_metrics_logreg = find_best_threshold(\n",
    "    model=best_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    metric=auto_best_threshold_based_on_metric,             \n",
    "    bootstrap=include_bootstrap_confidence_intervals,    # to get CI    \n",
    "    n_bootstrap=100         \n",
    ")\n",
    "\n",
    "print_metrics(metrics_dict=best_metrics_logreg)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "plot_confusion_mat(best_model, \n",
    "                   X_test, y_test, \n",
    "                   threshold=best_metrics_logreg['threshold'], \n",
    "                   labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "fig = plot_auc(y_test, y_test_proba)\n",
    "fig.show()\n",
    "# plot_auc_paper(y_test, y_test_proba)\n",
    "\n",
    "# #------------------------ Choosing a different threshold ------------------------\n",
    "\n",
    "# threshold_to_display = 0.5 \n",
    "\n",
    "# threshold_dict = evaluate_model_at_threshold(best_model, \n",
    "#                             X_test, y_test, \n",
    "#                             threshold=threshold_to_display, \n",
    "#                             bootstrap=include_bootstrap_confidence_intervals, \n",
    "#                             n_bootstrap=100)\n",
    "\n",
    "# print_metrics(metrics_dict=threshold_dict)\n",
    "\n",
    "# plot_confusion_mat(best_model, \n",
    "#                    X_test, y_test, \n",
    "#                    threshold=threshold_dict['threshold'], \n",
    "#                    labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "# #--------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f9b48",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) Classifier\n",
    "\n",
    "Support Vector Machines aim to find a hyperplane that maximally separates classes in the feature space. The separation is done by maximizing the margin between the classes, defined by the closest points (support vectors).\n",
    "\n",
    "#### Linear SVM\n",
    "\n",
    "Given labeled data $(\\mathbf{x}_i, y_i)$, where $\\mathbf{x}_i \\in \\mathbb{R}^n$ and $y_i \\in \\{-1, +1\\}$, SVM solves:\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{w}, b, \\boldsymbol{\\xi}} \\ \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^n \\xi_i\n",
    "$$\n",
    "$$\n",
    "\\text{subject to } \\ y_i(\\mathbf{w}^\\top \\mathbf{x}_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{w}$: weight vector (normal to the hyperplane)\n",
    "- $b$: bias term\n",
    "- $xi_i$: slack variables for misclassification\n",
    "- $C > 0$: regularization parameter\n",
    "\n",
    "\n",
    "##### Nonlinear SVM\n",
    "\n",
    "To handle nonlinear boundaries, SVM maps data into a higher-dimensional space via a kernel function $K(\\mathbf{x}_i, \\mathbf{x}_j)$:\n",
    "\n",
    "$$\n",
    "K(\\mathbf{x}_i, \\mathbf{x}_j) = \\phi(\\mathbf{x}_i)^\\top \\phi(\\mathbf{x}_j)\n",
    "$$\n",
    "\n",
    "Kernels:\n",
    "- Linear: $K(\\mathbf{x}, \\mathbf{z}) = \\mathbf{x}^\\top \\mathbf{z}$\n",
    "- RBF: $K(\\mathbf{x}, \\mathbf{z}) = \\exp(-\\gamma \\|\\mathbf{x} - \\mathbf{z}\\|^2)$\n",
    "- Polynomial: $K(\\mathbf{x}, \\mathbf{z}) = (\\mathbf{x}^\\top \\mathbf{z} + r)^d$\n",
    "\n",
    "\n",
    "The model:\n",
    "\n",
    "- Has no distributional assumptions.\n",
    "- Assumes classes are separable with margin.\n",
    "- Is sensitive to feature scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411315c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ----------------------------------------- Model Parameters  -----------------------------------------\n",
    "\n",
    "auto_best_threshold_based_on_metric = 'f1'      # Available metrics: [\"accuracy\", \"sensitivity\", \"specificity\", \"ppv\", \"npv\", \"f1\", \"auc\"]\n",
    "include_bootstrap_confidence_intervals = True        # True # False\n",
    "cross_validation_splits = 5                           # 5-Fold cross validation\n",
    "grid_search_scoring_metric = 'recall'                 # choosing best metric in grid search : ['roc_auc','recall']\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# scaling + SVM\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(probability=True, kernel='rbf', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# SVM hyperparameter grid\n",
    "svm_param_grid = {\n",
    "    'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'svc__gamma': ['scale', 'auto'],\n",
    "    'svc__kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=cross_validation_splits, shuffle=True, random_state=random_state)\n",
    "svm_grid = GridSearchCV(svm_pipe, svm_param_grid, cv=cv, scoring=grid_search_scoring_metric, n_jobs=-1) \n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"SVM best parameters:\", svm_grid.best_params_)\n",
    "\n",
    "# Test set evaluation\n",
    "svm_best = svm_grid.best_estimator_\n",
    "y_test_proba_svm = svm_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_metrics_svm = find_best_threshold(\n",
    "    model=svm_best,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    metric=auto_best_threshold_based_on_metric,             \n",
    "    bootstrap=include_bootstrap_confidence_intervals,    # to get CI    \n",
    "    n_bootstrap=100        \n",
    ")\n",
    "\n",
    "print_metrics(metrics_dict=best_metrics_svm)\n",
    "\n",
    "plot_confusion_mat(svm_best, \n",
    "                   X_test, y_test, \n",
    "                   threshold=best_metrics_svm['threshold'], \n",
    "                   labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "fig = plot_auc(y_test, y_test_proba_svm)\n",
    "fig.show()\n",
    "# plot_auc_paper(y_test, y_test_proba)\n",
    "\n",
    "# ------------------------ Choosing a different threshold ------------------------\n",
    "\n",
    "# threshold_to_display = 0.5 \n",
    "\n",
    "# threshold_dict = evaluate_model_at_threshold(svm_best, \n",
    "#                             X_test, y_test, \n",
    "#                             threshold=threshold_to_display, \n",
    "#                             bootstrap=include_bootstrap_confidence_intervals, \n",
    "#                             n_bootstrap=100)\n",
    "\n",
    "# print_metrics(metrics_dict=threshold_dict)\n",
    "\n",
    "# plot_confusion_mat(svm_best, \n",
    "#                    X_test, y_test, \n",
    "#                    threshold=threshold_dict['threshold'], \n",
    "#                    labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db293c14",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "A Decision Tree partitions the feature space into axis-aligned regions using recursive binary splits, aiming to maximize class purity.\n",
    "\n",
    "#### Model Definition\n",
    "\n",
    "Given data $(\\mathbf{x}_i, y_i)$, a tree is built by selecting splits that maximize an impurity reduction criterion.\n",
    "\n",
    "The impurity measure is the Gini impurity: $G = \\sum_{k=1}^K p_k(1 - p_k)$  \n",
    "\n",
    "Where $p_k$ is the proportion of class $k$ in a node.\n",
    "\n",
    "#### Properties\n",
    "\n",
    "- Interpretable and non-parametric.\n",
    "- Handles both numerical and categorical data.\n",
    "- Prone to overfitting without pruning.\n",
    "- No need for feature scaling.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "Random Forest is an ensemble method that constructs multiple decision trees and combines their outputs via majority voting.\n",
    "\n",
    "#### Model Definition\n",
    "\n",
    "Given labeled data $(\\mathbf{x}_i, y_i)$, where $\\mathbf{x}_i \\in \\mathbb{R}^n$ and $y_i \\in \\{1, \\dots, K\\}$, the Random Forest predicts class $\\hat{y}$ by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\arg\\max_{k \\in \\{1,\\dots,K\\}} \\sum_{t=1}^T \\mathbb{I}(h_t(\\mathbf{x}) = k)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $h_t$: prediction of the $t$-th tree\n",
    "- $T$: total number of trees\n",
    "\n",
    "#### Properties\n",
    "\n",
    "- Trained on bootstrap samples (with replacement).\n",
    "- Splits use random feature subsets.\n",
    "- No need for feature scaling.\n",
    "- Captures nonlinearity and feature interactions.\n",
    "- Reduces variance via averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ----------------------------------------- Model Parameters  -----------------------------------------\n",
    "\n",
    "auto_best_threshold_based_on_metric = 'accuracy'         # Available metrics: [\"accuracy\", \"sensitivity\", \"specificity\", \"ppv\", \"npv\", \"f1\", \"auc\"]\n",
    "include_bootstrap_confidence_intervals = True           # True # False\n",
    "cross_validation_splits = 5                              # 5-Fold cross validation\n",
    "grid_search_scoring_metric = 'recall'                    # choosing best metric in grid search : ['roc_auc','recall']\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=random_state, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Random Forest hyperparameter grid\n",
    "rf_param_grid = {\n",
    "    'rf__n_estimators': [100, 200],\n",
    "    'rf__max_depth': [None, 5, 10],\n",
    "    'rf__min_samples_split': [2, 5],\n",
    "    'rf__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=cross_validation_splits, shuffle=True, random_state=random_state)\n",
    "rf_grid = GridSearchCV(rf_pipe, rf_param_grid, cv=cv, scoring=grid_search_scoring_metric, n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest best parameters:\", rf_grid.best_params_)\n",
    "\n",
    "# Evaluate RF on test set\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_test_proba_rf = rf_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_metrics_rf = find_best_threshold(\n",
    "    model=rf_best,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    metric=auto_best_threshold_based_on_metric,             \n",
    "    bootstrap=include_bootstrap_confidence_intervals,    # to get CI    \n",
    "    n_bootstrap=100        \n",
    ")\n",
    "\n",
    "print_metrics(metrics_dict=best_metrics_rf)\n",
    "\n",
    "plot_confusion_mat(rf_best, \n",
    "                   X_test, y_test, \n",
    "                   threshold=best_metrics_rf['threshold'], \n",
    "                   labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "fig = plot_auc(y_test, y_test_proba_rf)\n",
    "fig.show()\n",
    "# plot_auc_paper(y_test, y_test_proba_rf)\n",
    "\n",
    "# #------------------------ Choosing a different threshold ------------------------\n",
    "\n",
    "# threshold_to_display = 0.3 \n",
    "\n",
    "# threshold_dict = evaluate_model_at_threshold(rf_best, \n",
    "#                             X_test, y_test, \n",
    "#                             threshold=threshold_to_display, \n",
    "#                             bootstrap=include_bootstrap_confidence_intervals, \n",
    "#                             n_bootstrap=100)\n",
    "\n",
    "# print_metrics(metrics_dict=threshold_dict)\n",
    "\n",
    "# plot_confusion_mat(rf_best, \n",
    "#                    X_test, y_test, \n",
    "#                    threshold=threshold_dict['threshold'], \n",
    "#                    labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "# #--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949a923",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine\n",
    "\n",
    "Gradient Boosting builds an additive model by sequentially fitting decision trees to correct the errors of prior models using gradient descent on a loss function.\n",
    "\n",
    "#### Model Definition\n",
    "\n",
    "Given data $(\\mathbf{x}_i, y_i)$, the prediction is:\n",
    "\n",
    "$$\n",
    "F_M(\\mathbf{x}) = \\sum_{m=1}^M \\gamma_m h_m(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $h_m(\\mathbf{x})$: the $m$-th weak learner (decision tree).\n",
    "- $\\gamma_m$: step size\n",
    "- $M$: number of boosting rounds\n",
    "\n",
    "Each $h_m$ is fit to the negative gradient of the loss function $\\ell$:\n",
    "\n",
    "$$\n",
    "r_i^{(m)} = -\\left[\\frac{\\partial \\ell(y_i, F(\\mathbf{x}_i))}{\\partial F(\\mathbf{x}_i)}\\right]_{F = F_{m-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ecd98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGM\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# ----------------------------------------- Model Parameters  -----------------------------------------\n",
    "\n",
    "auto_best_threshold_based_on_metric = 'accuracy'       # Available metrics: [\"accuracy\", \"sensitivity\", \"specificity\", \"ppv\", \"npv\", \"f1\", \"auc\"]\n",
    "include_bootstrap_confidence_intervals = True          # True # False\n",
    "cross_validation_splits = 5                            # 5-Fold cross validation\n",
    "grid_search_scoring_metric = 'recall'                 # choosing best metric in grid search : ['roc_auc','recall']\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "gb_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Gradient Boosting hyperparameter grid\n",
    "gb_param_grid = {\n",
    "    'gb__n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'gb__learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "    'gb__max_depth': [2, 3, 5, 7]\n",
    "}\n",
    "\n",
    "sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "cv = StratifiedKFold(n_splits=cross_validation_splits, shuffle=True, random_state=random_state)\n",
    "gb_grid = GridSearchCV(gb_pipe, gb_param_grid, cv=cv, scoring=grid_search_scoring_metric, n_jobs=-1)\n",
    "gb_grid.fit(X_train, y_train, gb__sample_weight=sample_weight)\n",
    "\n",
    "print(\"Gradient Boosting best parameters:\", gb_grid.best_params_)\n",
    "\n",
    "# Evaluate GB on test set\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_test_proba_gb = gb_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "best_metrics_gb = find_best_threshold(\n",
    "    model=gb_best,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    metric=auto_best_threshold_based_on_metric,             \n",
    "    bootstrap=include_bootstrap_confidence_intervals,    # to get CI    \n",
    "    n_bootstrap=100        \n",
    ")\n",
    "\n",
    "print_metrics(metrics_dict=best_metrics_gb)\n",
    "\n",
    "plot_confusion_mat(gb_best, \n",
    "                   X_test, y_test, \n",
    "                   threshold=best_metrics_gb['threshold'], \n",
    "                   labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "fig = plot_auc(y_test, y_test_proba_gb)\n",
    "fig.show()\n",
    "# plot_auc_paper(y_test, y_test_proba_gb)\n",
    "\n",
    "# ------------------------ Choosing a different threshold ------------------------\n",
    "\n",
    "# threshold_to_display = 0.5 \n",
    "\n",
    "# threshold_dict = evaluate_model_at_threshold(gb_best, \n",
    "#                             X_test, y_test, \n",
    "#                             threshold=threshold_to_display, \n",
    "#                             bootstrap=include_bootstrap_confidence_intervals, \n",
    "#                             n_bootstrap=100)\n",
    "\n",
    "# print_metrics(metrics_dict=threshold_dict)\n",
    "\n",
    "# plot_confusion_mat(gb_best, \n",
    "#                    X_test, y_test, \n",
    "#                    threshold=threshold_dict['threshold'], \n",
    "#                    labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf815323",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors (KNN)\n",
    "\n",
    "k-NN is a non-parametric, instance-based learning algorithm that predicts the output of a query point based on the outputs of its *k* nearest neighbors in the training set.\n",
    "\n",
    "#### Model Definition\n",
    "\n",
    "Given a query point $\\mathbf{x}$ and a training set $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$, the prediction $\\hat{y}$ is:\n",
    "\n",
    "- **For regression**:\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{k} \\sum_{i \\in \\mathcal{N}_k(\\mathbf{x})} y_i\n",
    "$$\n",
    "\n",
    "- **For classification**:\n",
    "$$\n",
    "\\hat{y} = \\text{mode}\\left(\\{y_i \\mid i \\in \\mathcal{N}_k(\\mathbf{x})\\}\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mathcal{N}_k(\\mathbf{x})$: indices of the $k$ nearest neighbors to $\\mathbf{x}$.\n",
    "\n",
    "No explicit training is performed; computation occurs at prediction time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea711c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ----------------------------------------- Model Parameters  -----------------------------------------\n",
    "\n",
    "auto_best_threshold_based_on_metric = 'accuracy'      # Available metrics: [\"accuracy\", \"sensitivity\", \"specificity\", \"ppv\", \"npv\", \"f1\", \"auc\"]\n",
    "include_bootstrap_confidence_intervals = True        # True # False\n",
    "cross_validation_splits = 5                           # 5-Fold cross validation\n",
    "grid_search_scoring_metric = 'roc_auc'                 # choosing best metric in grid search : ['roc_auc','recall']\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# KNN hyperparameter grid\n",
    "knn_param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=cross_validation_splits, shuffle=True, random_state=random_state)\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_param_grid, cv=cv, scoring=grid_search_scoring_metric, n_jobs=-1)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"KNN best parameters:\", knn_grid.best_params_)\n",
    "\n",
    "# Evaluate KNN on test set\n",
    "knn_best = knn_grid.best_estimator_\n",
    "y_test_proba_knn = knn_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_metrics_knn = find_best_threshold(\n",
    "    model=knn_best,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    metric=auto_best_threshold_based_on_metric,\n",
    "    bootstrap=include_bootstrap_confidence_intervals,\n",
    "    n_bootstrap=100\n",
    ")\n",
    "\n",
    "print_metrics(metrics_dict=best_metrics_knn)\n",
    "\n",
    "plot_confusion_mat(knn_best,\n",
    "                   X_test, y_test,\n",
    "                   threshold=best_metrics_knn['threshold'],\n",
    "                   labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "fig = plot_auc(y_test, y_test_proba_knn)\n",
    "fig.show()\n",
    "# plot_auc_paper(y_test, y_test_proba_knn)\n",
    "\n",
    "# ------------------------ Choosing a different threshold ------------------------\n",
    "\n",
    "# threshold_to_display = 0.08\n",
    "\n",
    "# threshold_dict = evaluate_model_at_threshold(knn_best, \n",
    "#                             X_test, y_test, \n",
    "#                             threshold=threshold_to_display, \n",
    "#                             bootstrap=include_bootstrap_confidence_intervals, \n",
    "#                             n_bootstrap=100)\n",
    "\n",
    "# print_metrics(metrics_dict=threshold_dict)\n",
    "\n",
    "# plot_confusion_mat(knn_best, \n",
    "#                    X_test, y_test, \n",
    "#                    threshold=threshold_dict['threshold'], \n",
    "#                    labels=[\"Human\", \"Robot\"])\n",
    "\n",
    "# --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between the models\n",
    "\n",
    "fig_radar = radar_metrics_multi(\n",
    "    [best_metrics_logreg, best_metrics_svm, best_metrics_rf, best_metrics_gb, best_metrics_knn],\n",
    "    [\"Logistic Regression\", \"SVM\", \"Random Forest\", \"GBM\", \"KNN\"])\n",
    "fig_radar.show()\n",
    "\n",
    "# fig = radar_metrics_multi_matplotlib(\n",
    "#     [best_metrics_logreg, best_metrics_svm, best_metrics_rf, best_metrics_gb, best_metrics_knn],\n",
    "#     [\"Logistic Regression\", \"SVM\", \"Random Forest\", \"GBM\", \"KNN\"])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare feature names and importance values\n",
    "features = X_train.columns\n",
    "logreg_vals = abs(best_model.coef_[0])\n",
    "rf_vals = rf_best.named_steps['rf'].feature_importances_\n",
    "gb_vals = gb_best.named_steps['gb'].feature_importances_\n",
    "\n",
    "# Sort by importance\n",
    "def sort_features(features, importances):\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "    return np.array(features)[sorted_idx], np.array(importances)[sorted_idx]\n",
    "\n",
    "logreg_features, logreg_vals = sort_features(features, logreg_vals)\n",
    "rf_features, rf_vals = sort_features(features, rf_vals)\n",
    "gb_features, gb_vals = sort_features(features, gb_vals)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3), sharey=True)\n",
    "\n",
    "bars0 = axes[0].barh(logreg_features, logreg_vals, color='skyblue')\n",
    "axes[0].set_title(\"Logistic Regression\\n(Absolute Coefficients)\")\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].bar_label(bars0, fmt='%.3f')\n",
    "\n",
    "bars1 = axes[1].barh(rf_features, rf_vals, color='lightgreen')\n",
    "axes[1].set_title(\"Random Forest\\n(Mean Decrease in Impurity)\")\n",
    "axes[1].bar_label(bars1, fmt='%.3f')\n",
    "\n",
    "bars2 = axes[2].barh(gb_features, gb_vals, color='salmon')\n",
    "axes[2].set_title(\"Gradient Boosting\\n(Mean Decrease in Impurity)\")\n",
    "axes[2].bar_label(bars2, fmt='%.3f')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b8bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
